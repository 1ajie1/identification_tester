"""
GPUåŠ é€ŸYOLOæ£€æµ‹ç¤ºä¾‹
ä½¿ç”¨é…ç½®å¥½çš„ç¯å¢ƒè¿›è¡ŒGPUåŠ é€Ÿçš„YOLOç›®æ ‡æ£€æµ‹
"""

import torch
import cv2
import numpy as np
from ultralytics import YOLO
import time

def check_gpu_status():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    print("=== GPUçŠ¶æ€æ£€æŸ¥ ===")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUè®¾å¤‡æ•°: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"GPU {i} å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
    
    print(f"NumPyç‰ˆæœ¬: {np.__version__}")
    print(f"OpenCVç‰ˆæœ¬: {cv2.__version__}")

def create_yolo_model(model_name='yolo11n.pt'):
    """åˆ›å»ºYOLOæ¨¡å‹å¹¶é…ç½®GPU"""
    print(f"\n=== åŠ è½½YOLOæ¨¡å‹: {model_name} ===")
    
    try:
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_name)
        print("âœ“ YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # è®¾ç½®è®¾å¤‡
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        model.to(device)
        print(f"âœ“ æ¨¡å‹è®¾å¤‡: {device}")
        
        return model, device
    
    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None

def benchmark_inference(model, device, image_size=(640, 640), num_runs=10):
    """åŸºå‡†æµ‹è¯•æ¨ç†æ€§èƒ½"""
    if model is None:
        print("æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡åŸºå‡†æµ‹è¯•")
        return
    
    print(f"\n=== æ¨ç†æ€§èƒ½æµ‹è¯• ({device}) ===")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (*image_size, 3), dtype=np.uint8)
    
    # é¢„çƒ­GPU
    print("é¢„çƒ­GPU...")
    for _ in range(3):
        _ = model(test_image, verbose=False)
    
    # æ€§èƒ½æµ‹è¯•
    times = []
    print(f"å¼€å§‹{num_runs}æ¬¡æ¨ç†æµ‹è¯•...")
    
    for i in range(num_runs):
        start_time = time.time()
        results = model(test_image, verbose=False)
        end_time = time.time()
        inference_time = end_time - start_time
        times.append(inference_time)
        print(f"æ¨ç† {i+1:2d}: {inference_time:.4f}s")
    
    # ç»Ÿè®¡ç»“æœ
    avg_time = np.mean(times)
    min_time = np.min(times)
    max_time = np.max(times)
    fps = 1.0 / avg_time
    
    print(f"\næ€§èƒ½ç»Ÿè®¡:")
    print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.4f}s")
    print(f"æœ€å¿«æ¨ç†æ—¶é—´: {min_time:.4f}s")
    print(f"æœ€æ…¢æ¨ç†æ—¶é—´: {max_time:.4f}s")
    print(f"å¹³å‡FPS: {fps:.2f}")

def detect_objects_in_image(model, image_path, save_path=None):
    """åœ¨å›¾åƒä¸­æ£€æµ‹ç›®æ ‡"""
    if model is None:
        print("æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡ç›®æ ‡æ£€æµ‹")
        return
    
    print(f"\n=== å›¾åƒç›®æ ‡æ£€æµ‹: {image_path} ===")
    
    try:
        # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
        image = cv2.imread(image_path)
        if image is None:
            print(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return
        
        print(f"å›¾åƒå°ºå¯¸: {image.shape}")
        
        # è¿›è¡Œæ£€æµ‹
        start_time = time.time()
        results = model(image_path)
        inference_time = time.time() - start_time
        
        print(f"æ¨ç†æ—¶é—´: {inference_time:.4f}s")
        
        # å¤„ç†ç»“æœ
        for r in results:
            boxes = r.boxes
            if boxes is not None and len(boxes) > 0:
                print(f"æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡:")
                for i, box in enumerate(boxes):
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    class_name = model.names[cls]
                    print(f"  {i+1}. {class_name}: {conf:.3f}")
                
                # ä¿å­˜æ ‡æ³¨å›¾åƒ
                if save_path:
                    annotated_frame = r.plot()
                    cv2.imwrite(save_path, annotated_frame)
                    print(f"æ ‡æ³¨å›¾åƒå·²ä¿å­˜: {save_path}")
            else:
                print("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
    
    except Exception as e:
        print(f"æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("GPUåŠ é€ŸYOLOæ£€æµ‹ç¤ºä¾‹")
    print("=" * 50)
    
    # æ£€æŸ¥GPUçŠ¶æ€
    check_gpu_status()
    
    # åˆ›å»ºæ¨¡å‹
    model, device = create_yolo_model()
    
    if model is None:
        print("æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    benchmark_inference(model, device)
    
    # æ£€æµ‹ç¤ºä¾‹å›¾åƒ
    test_images = ['tmp/bus.jpg', 'tmp/test.jpg']
    
    for img_path in test_images:
        try:
            if cv2.imread(img_path) is not None:
                output_path = f"tmp/output_{img_path.split('/')[-1]}"
                detect_objects_in_image(model, img_path, output_path)
                break
        except:
            continue
    else:
        print("\næœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œåˆ›å»ºéšæœºå›¾åƒè¿›è¡Œæ¼”ç¤º...")
        # åˆ›å»ºéšæœºæµ‹è¯•å›¾åƒ
        random_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        test_path = 'tmp/random_test.jpg'
        cv2.imwrite(test_path, random_image)
        detect_objects_in_image(model, test_path, 'tmp/output_random.jpg')
    
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹å®Œæˆï¼")
    
    if torch.cuda.is_available():
        print("ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨ï¼Œäº«å—å¿«é€Ÿçš„YOLOæ£€æµ‹ï¼")
    else:
        print("âš  ä½¿ç”¨CPUæ¨¡å¼ï¼Œè€ƒè™‘å®‰è£…CUDAä»¥è·å¾—æ›´å¥½æ€§èƒ½")

if __name__ == "__main__":
    main()
