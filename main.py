import ctypes
import sys
import os
import json
import numpy as np
import logging


from PySide6.QtGui import QGuiApplication
from PySide6.QtQml import QmlElement, QQmlApplicationEngine
from PySide6.QtCore import QObject, Signal, Slot, Property, QUrl, Qt
print("ç­–ç•¥ï¼š", QGuiApplication.highDpiScaleFactorRoundingPolicy())

from python.template_matching import template_matcher
from python.feature_matching import orb_matcher
from python.screen_capture import screen_capture
from python.yolo_orb_matching import yolo_orb_matcher
from python.yolo_matching_pure import pure_yolo_matcher

QML_IMPORT_NAME = "ImageMatcher"

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
QML_IMPORT_MAJOR_VERSION = 1


@QmlElement
class ImageMatcherController(QObject):
    # ä¿¡å·å®šä¹‰
    modeChanged = Signal(int)  # æ¨¡å¼æ”¹å˜ä¿¡å· (0: åŒå›¾ç‰‡æ¨¡å¼, 1: å±å¹•çª—å£æ¨¡å¼)
    algorithmModeChanged = Signal(
        int
    )  # ç®—æ³•æ¨¡å¼æ”¹å˜ä¿¡å· (0: æ¨¡æ¿åŒ¹é…, 1: ORB, 2: YOLO+ORB, 3: çº¯YOLO)
    needleImage = Signal(str)  # ç¬¬ä¸€å¼ å›¾ç‰‡é€‰æ‹©ä¿¡å·
    haystackImage = Signal(str)  # ç¬¬äºŒå¼ å›¾ç‰‡é€‰æ‹©ä¿¡å·
    windowSelected = Signal(str)  # å±å¹•çª—å£é€‰æ‹©ä¿¡å·
    screenAreaImageChanged = Signal(str)  # å±å¹•åŒºåŸŸå›¾ç‰‡å˜æ›´ä¿¡å·
    logAdded = Signal(str, str)  # æ—¥å¿—æ·»åŠ ä¿¡å· (message, type)
    showMatchResult = Signal(str, str)  # æ˜¾ç¤ºåŒ¹é…ç»“æœä¿¡å· (image_path, title)
    showScreenMatchOverlay = Signal(
        int, int, int, int, float, str
    )  # æ˜¾ç¤ºå±å¹•åŒ¹é…è¦†ç›–å±‚ (x, y, width, height, confidence, title)
    showMultipleDetections = Signal(str)  # æ˜¾ç¤ºå¤šä¸ªæ£€æµ‹ç»“æœ (detections_json)
    realtimeDetectionStateChanged = Signal(bool)  # å®æ—¶æ£€æµ‹çŠ¶æ€å˜åŒ– (active)
    clearAllDetections = Signal()  # æ¸…é™¤æ‰€æœ‰æ£€æµ‹ç»“æœ

    def __init__(self):
        super().__init__()
        self._current_mode = 0  # 0: åŒå›¾ç‰‡æ¨¡å¼, 1: å±å¹•çª—å£æ¨¡å¼
        self._algorithm_mode = 0  # 0: æ¨¡æ¿åŒ¹é…, 1: ORB, 2: YOLO+ORB, 3: çº¯YOLO
        self._image1_path = ""
        self._image2_path = ""
        self._selected_window = ""
        self._selected_window_rect = {"x": 0, "y": 0, "width": 0, "height": 0}
        self._screen_area_image_path = ""  # å±å¹•åŒºåŸŸæˆªå›¾è·¯å¾„
        self._area_capture_timer = None  # åŒºåŸŸæˆªå–å®šæ—¶å™¨
        
        # å®æ—¶æ£€æµ‹ç›¸å…³
        self._realtime_detection_active = False
        self._realtime_timer = None
        self._realtime_interval = 500  # æ¯«ç§’ï¼Œæ£€æµ‹é—´éš”
        
        # åŠ¨æ€é¢œè‰²æ˜ å°„
        self._class_colors = {}  # ç±»åˆ«IDåˆ°é¢œè‰²çš„æ˜ å°„
        self._model_classes = {}  # æ¨¡å‹ç±»åˆ«ä¿¡æ¯

        # ç®—æ³•é…ç½®å‚æ•°
        self._algorithm_settings = {
            0: {  # æ¨¡æ¿åŒ¹é…
                "method": "TM_CCOEFF_NORMED",
                "threshold": 0.8,
                "max_retries": 3,
                "retry_delay": 1.0,
            },
            1: {  # ORBç‰¹å¾åŒ¹é…
                "nfeatures": 1000,
                "scaleFactor": 1.2,
                "nlevels": 8,
                "edgeThreshold": 15,
                "fastThreshold": 10,
                "distance_threshold": 0.8,
                "min_matches": 4,
                "max_retries": 3,
                "use_ratio_test": False,
                "use_cross_check": False,
            },
            2: {  # YOLO+ORBæ··åˆ
                "yolo_confidence": 0.5,
                "nms_threshold": 0.4,
                "orb_nfeatures": 500,
                "model_path": "",
            },
            3: {  # çº¯YOLO
                "confidence_threshold": 0.5,
                "nms_threshold": 0.4,
                "model_path": "",
            },
        }

    # å½“å‰æ¨¡å¼å±æ€§
    @Property(int, notify=modeChanged)
    def currentMode(self):
        return self._current_mode

    @currentMode.setter
    def currentMode(self, mode):
        if self._current_mode != mode:
            self._current_mode = mode
            self.modeChanged.emit(mode)

    # ç®—æ³•æ¨¡å¼å±æ€§
    @Property(int, notify=algorithmModeChanged)
    def algorithmMode(self):
        return self._algorithm_mode

    @algorithmMode.setter
    def algorithmMode(self, mode):
        if self._algorithm_mode != mode:
            self._algorithm_mode = mode
            self.algorithmModeChanged.emit(mode)

    # å›¾ç‰‡è·¯å¾„å±æ€§
    @Property(str, notify=needleImage)
    def image1Path(self):
        return self._image1_path

    @Property(str, notify=haystackImage)
    def image2Path(self):
        return self._image2_path

    @Property(str, notify=windowSelected)
    def selectedWindow(self):
        return self._selected_window

    @Property('QVariant', notify=windowSelected)
    def selectedWindowRect(self):
        return self._selected_window_rect

    @Property(str, notify=screenAreaImageChanged)
    def screenAreaImagePath(self):
        return self._screen_area_image_path

    @Slot(int)
    def switchMode(self, mode):
        """åˆ‡æ¢è¾“å…¥æ¨¡å¼"""
        # å¦‚æœåˆ‡æ¢åˆ°åŒå›¾ç‰‡æ¨¡å¼ï¼Œåœæ­¢åŒºåŸŸæˆªå–
        if mode == 0 and self._area_capture_timer:
            self._area_capture_timer.stop()
            self._area_capture_timer = None
            self._screen_area_image_path = ""
            self.screenAreaImageChanged.emit("")
            self.logAdded.emit("å·²åœæ­¢å±å¹•åŒºåŸŸå®æ—¶æ˜¾ç¤º", "info")

        self.currentMode = mode
        print(f"åˆ‡æ¢åˆ°è¾“å…¥æ¨¡å¼: {'åŒå›¾ç‰‡åŒ¹é…' if mode == 0 else 'å±å¹•çª—å£åŒ¹é…'}")

    @Slot(int)
    def switchAlgorithmMode(self, mode):
        """åˆ‡æ¢ç®—æ³•æ¨¡å¼"""
        self.algorithmMode = mode
        algorithm_names = [
            "æ¨¡æ¿åŒ¹é…",
            "OpenCV ORBç‰¹å¾åŒ¹é…",
            "YOLO+ORBæ··åˆåŒ¹é…",
            "çº¯YOLOåŒ¹é…",
        ]
        print(f"åˆ‡æ¢åˆ°ç®—æ³•æ¨¡å¼: {algorithm_names[mode]}")

    @Slot(str)
    def selectImage1(self, path):
        """é€‰æ‹©ç¬¬ä¸€å¼ å›¾ç‰‡"""
        self._image1_path = path
        self.needleImage.emit(path)
        print(f"é€‰æ‹©ç¬¬ä¸€å¼ å›¾ç‰‡: {path}")

    @Slot(str)
    def selectImage2(self, path):
        """é€‰æ‹©ç¬¬äºŒå¼ å›¾ç‰‡"""
        self._image2_path = path
        self.haystackImage.emit(path)
        print(f"é€‰æ‹©ç¬¬äºŒå¼ å›¾ç‰‡: {path}")

    @Slot(str, str, result=str)
    def selectWindow(self, window_title, window_rect_json=""):
        """é€‰æ‹©å±å¹•çª—å£"""
        self._selected_window = window_title

        # è§£æçª—å£çŸ©å½¢ä¿¡æ¯
        if window_rect_json:
            try:
                import json

                rect_data = json.loads(window_rect_json)
                self._selected_window_rect = {
                    "x": rect_data.get("x", 0),
                    "y": rect_data.get("y", 0),
                    "width": rect_data.get("width", 0),
                    "height": rect_data.get("height", 0),
                }
            except:
                self._selected_window_rect = {"x": 0, "y": 0, "width": 0, "height": 0}

        self.windowSelected.emit(window_title)
        print(f"é€‰æ‹©çª—å£: {window_title}, åŒºåŸŸ: {self._selected_window_rect}")
        return "success"

    @Slot(str, result=str)
    def selectScreenArea(self, area_rect_json):
        """é€‰æ‹©å±å¹•åŒºåŸŸ"""
        try:
            import json
            import os
            import tempfile
            from PySide6.QtCore import QTimer

            rect_data = json.loads(area_rect_json)

            # ä¿ç•™ä¸€ä½å°æ•°
            x = round(rect_data.get("x", 0), 1)
            y = round(rect_data.get("y", 0), 1)
            width = round(rect_data.get("width", 0), 1)
            height = round(rect_data.get("height", 0), 1)

            self._selected_window_rect = {
                "x": x,
                "y": y,
                "width": width,
                "height": height,
            }

            area_info = f"å±å¹•åŒºåŸŸ ({x}, {y}, {width}Ã—{height})"
            self._selected_window = area_info

            # åœæ­¢ä¹‹å‰çš„å®šæ—¶å™¨
            if self._area_capture_timer:
                self._area_capture_timer.stop()
                self._area_capture_timer = None

            # åˆ›å»ºå®šæ—¶å™¨ï¼Œæ¯33msæˆªå–ä¸€æ¬¡å±å¹•åŒºåŸŸï¼ˆ30FPSï¼‰
            self._area_capture_timer = QTimer()
            self._area_capture_timer.timeout.connect(self._captureScreenArea)
            self._area_capture_timer.start(33)  # 33msé—´éš”ï¼Œçº¦30FPS

            # ç«‹å³æˆªå–ä¸€æ¬¡
            self._captureScreenArea()

            self.windowSelected.emit(area_info)
            self.logAdded.emit(f"å¼€å§‹å®æ—¶æ˜¾ç¤ºå±å¹•åŒºåŸŸ: {area_info}", "success")
            print(f"é€‰æ‹©å±å¹•åŒºåŸŸ: {self._selected_window_rect}")
            return "success"

        except Exception as e:
            print(f"è§£æå±å¹•åŒºåŸŸå¤±è´¥: {e}")
            self._selected_window_rect = {"x": 0, "y": 0, "width": 0, "height": 0}
            self.logAdded.emit(f"é€‰æ‹©å±å¹•åŒºåŸŸå¤±è´¥: {str(e)}", "error")
            return "error"

    def _captureScreenArea(self):
        """æˆªå–å±å¹•åŒºåŸŸ"""
        try:
            import os
            import tempfile
            import cv2
            import logging
            from datetime import datetime
            
            logger = logging.getLogger(__name__)

            if (
                self._selected_window_rect["width"] <= 0
                or self._selected_window_rect["height"] <= 0
            ):
                return

            # è·å–QMLä¼ é€’çš„é€»è¾‘åæ ‡
            logical_x = self._selected_window_rect["x"]
            logical_y = self._selected_window_rect["y"]
            logical_width = self._selected_window_rect["width"]
            logical_height = self._selected_window_rect["height"]
            
            # å°†é€»è¾‘åæ ‡è½¬æ¢ä¸ºç‰©ç†åæ ‡
            # QMLè¿”å›çš„æ˜¯é€»è¾‘åæ ‡ï¼Œéœ€è¦ä¹˜ä»¥DPIç¼©æ”¾å› å­å¾—åˆ°ç‰©ç†åƒç´ åæ ‡
            physical_x = int(logical_x * screen_capture.dpi_scale)
            physical_y = int(logical_y * screen_capture.dpi_scale)
            physical_width = int(logical_width * screen_capture.dpi_scale)
            physical_height = int(logical_height * screen_capture.dpi_scale)
            
            region = (physical_x, physical_y, physical_width, physical_height)
          
            # ä½¿ç”¨æˆ‘ä»¬ä¿®å¤çš„æˆªå›¾åŠŸèƒ½
            screenshot_cv = screen_capture.capture_screen(region)
            
            if screenshot_cv is None:
                print("å±å¹•åŒºåŸŸæˆªå›¾å¤±è´¥")
                return

            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            filename = f"screen_area_{timestamp}.png"
            filepath = os.path.join(temp_dir, filename)

            # ä½¿ç”¨OpenCVä¿å­˜å›¾åƒ
            success = cv2.imwrite(filepath, screenshot_cv)
            if not success:
                print(f"ä¿å­˜æˆªå›¾å¤±è´¥: {filepath}")
                return
            
            # æ¸…ç†æ—§æ–‡ä»¶ï¼ˆä¿ç•™æœ€è¿‘5ä¸ªï¼‰
            self._cleanupOldScreenshots(temp_dir)

            # æ›´æ–°è·¯å¾„å¹¶å‘é€ä¿¡å·
            old_path = self._screen_area_image_path
            self._screen_area_image_path = filepath
            self.screenAreaImageChanged.emit(filepath)

            # åˆ é™¤æ—§æ–‡ä»¶
            if old_path and os.path.exists(old_path) and old_path != filepath:
                try:
                    os.remove(old_path)
                except:
                    pass

        except Exception as e:
            print(f"æˆªå–å±å¹•åŒºåŸŸå¤±è´¥: {e}")
            self.logAdded.emit(f"æˆªå–å±å¹•åŒºåŸŸå¤±è´¥: {str(e)}", "error")

    def _cleanupOldScreenshots(self, temp_dir):
        """æ¸…ç†æ—§çš„æˆªå›¾æ–‡ä»¶"""
        try:
            import glob
            import os

            # æ‰¾åˆ°æ‰€æœ‰screen_area_å¼€å¤´çš„æ–‡ä»¶
            pattern = os.path.join(temp_dir, "screen_area_*.png")
            files = glob.glob(pattern)

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„5ä¸ª
            files.sort(key=os.path.getmtime, reverse=True)

            # åˆ é™¤å¤šä½™çš„æ–‡ä»¶
            for file_to_delete in files[5:]:
                try:
                    os.remove(file_to_delete)
                except:
                    pass
        except Exception as e:
            print(f"æ¸…ç†æ—§æˆªå›¾å¤±è´¥: {e}")

    @Slot()
    def startMatching(self):
        """å¼€å§‹åŒ¹é…"""
        # æ¸…é™¤ä¹‹å‰çš„æ£€æµ‹ç»“æœ
        self.clearAllDetections.emit()
        
        algorithm_names = [
            "æ¨¡æ¿åŒ¹é…",
            "OpenCV ORBç‰¹å¾åŒ¹é…",
            "YOLO+ORBæ··åˆåŒ¹é…",
            "çº¯YOLOåŒ¹é…",
        ]
        current_settings = self.getCurrentAlgorithmSettings()

        self.logAdded.emit(
            f"å¼€å§‹æ‰§è¡ŒåŒ¹é… - ç®—æ³•: {algorithm_names[self._algorithm_mode]}", "info"
        )
        self.logAdded.emit(f"ç®—æ³•å‚æ•°: {current_settings}", "info")

        if self._current_mode == 0:
            # åŒå›¾ç‰‡åŒ¹é…æ¨¡å¼
            if not self._image1_path or not self._image2_path:
                self.logAdded.emit("è¯·å…ˆé€‰æ‹©ä¸¤å¼ å›¾ç‰‡", "error")
                return

            if not os.path.exists(self._image1_path) or not os.path.exists(
                self._image2_path
            ):
                self.logAdded.emit("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨", "error")
                return

            self.logAdded.emit(
                f"æ¨¡æ¿å›¾ç‰‡: {os.path.basename(self._image1_path)}", "info"
            )
            self.logAdded.emit(
                f"ç›®æ ‡å›¾ç‰‡: {os.path.basename(self._image2_path)}", "info"
            )

            if self._algorithm_mode == 0:  # æ¨¡æ¿åŒ¹é…
                self._executeImageTemplateMatching()
            elif self._algorithm_mode == 1:  # ORBç‰¹å¾åŒ¹é…
                self._executeORBMatching()
            elif self._algorithm_mode == 2:  # YOLO+ORBæ··åˆ
                self._executeYOLOORBMatching()
            elif self._algorithm_mode == 3:  # çº¯YOLO
                self._executePureYOLOMatching()

        else:
            # å±å¹•çª—å£åŒ¹é…æ¨¡å¼
            if not self._selected_window:
                self.logAdded.emit("è¯·å…ˆé€‰æ‹©ç›®æ ‡çª—å£", "error")
                return

            # å¯¹äºçº¯YOLOæ¨¡å¼ï¼Œä¸éœ€è¦æ¨¡æ¿å›¾ç‰‡
            if self._algorithm_mode != 3:  # éçº¯YOLOæ¨¡å¼éœ€è¦æ¨¡æ¿å›¾ç‰‡
                if not self._image1_path:
                    self.logAdded.emit("è¯·å…ˆé€‰æ‹©æ¨¡æ¿å›¾ç‰‡", "error")
                    return

                if not os.path.exists(self._image1_path):
                    self.logAdded.emit("æ¨¡æ¿å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨", "error")
                    return

                self.logAdded.emit(
                    f"æ¨¡æ¿å›¾ç‰‡: {os.path.basename(self._image1_path)}", "info"
                )

            self.logAdded.emit(f"ç›®æ ‡çª—å£: {self._selected_window}", "info")

            if self._algorithm_mode == 0:  # æ¨¡æ¿åŒ¹é…
                self._executeScreenTemplateMatching()
            elif self._algorithm_mode == 1:  # ORBç‰¹å¾åŒ¹é…
                self._executeScreenORBMatching()
            elif self._algorithm_mode == 2:  # YOLO+ORBæ··åˆ
                self._executeScreenYOLOORBMatching()
            elif self._algorithm_mode == 3:  # çº¯YOLO
                self._executeScreenPureYOLOMatching()

    def _executeImageTemplateMatching(self):
        """æ‰§è¡Œå›¾ç‰‡é—´çš„æ¨¡æ¿åŒ¹é…"""
        try:
            import cv2
            import numpy as np

            config = self.getCurrentAlgorithmSettings()

            # è¯»å–å›¾ç‰‡
            template = cv2.imread(self._image1_path, cv2.IMREAD_COLOR)
            target = cv2.imread(self._image2_path, cv2.IMREAD_COLOR)

            if template is None or target is None:
                self.logAdded.emit("æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶", "error")
                return

            # è·å–åŒ¹é…å‚æ•°
            method_name = config.get("method", "TM_CCOEFF_NORMED")
            threshold = config.get("threshold", 0.8)
            max_retries = config.get("max_retries", 3)
            retry_delay = config.get("retry_delay", 1.0)

            # æ–¹æ³•æ˜ å°„
            methods = {
                "TM_CCOEFF_NORMED": cv2.TM_CCOEFF_NORMED,
                "TM_CCORR_NORMED": cv2.TM_CCORR_NORMED,
                "TM_SQDIFF_NORMED": cv2.TM_SQDIFF_NORMED,
            }

            method = methods.get(method_name, cv2.TM_CCOEFF_NORMED)

            self.logAdded.emit(f"å¼€å§‹æ¨¡æ¿åŒ¹é…ï¼Œæ–¹æ³•: {method_name}", "info")

            # æ‰§è¡ŒåŒ¹é…
            result = cv2.matchTemplate(target, template, method)
            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)

            # æ ¹æ®æ–¹æ³•é€‰æ‹©åˆé€‚çš„å€¼å’Œä½ç½®
            if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:
                match_val = min_val
                match_loc = min_loc
                confidence = 1 - match_val
            else:
                match_val = max_val
                match_loc = max_loc
                confidence = match_val

            template_h, template_w = template.shape[:2]

            if confidence >= threshold:
                # åŒ¹é…æˆåŠŸ
                center_x = match_loc[0] + template_w // 2
                center_y = match_loc[1] + template_h // 2

                self.logAdded.emit(f"åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(
                    f"åŒ¹é…ä½ç½®: ({match_loc[0]}, {match_loc[1]})", "success"
                )
                self.logAdded.emit(f"ä¸­å¿ƒç‚¹: ({center_x}, {center_y})", "success")
                self.logAdded.emit(f"ç½®ä¿¡åº¦: {confidence:.3f}", "success")
                self.logAdded.emit(f"æ¨¡æ¿å°ºå¯¸: {template_w} x {template_h}", "info")

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showMatchResult(
                    target, match_loc, template_w, template_h, confidence
                )

            else:
                self.logAdded.emit(
                    f"åŒ¹é…å¤±è´¥ï¼Œç½®ä¿¡åº¦ {confidence:.3f} ä½äºé˜ˆå€¼ {threshold}", "warning"
                )

        except Exception as e:
            self.logAdded.emit(f"æ¨¡æ¿åŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeScreenTemplateMatching(self):
        """æ‰§è¡Œå±å¹•æ¨¡æ¿åŒ¹é…"""
        try:
            config = self.getCurrentAlgorithmSettings()
            result = template_matcher.find_template_on_screen(self._image1_path, config)

            if result:
                self.logAdded.emit("å±å¹•åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(
                    f"åŒ¹é…ä½ç½®: ({result['left']}, {result['top']})", "success"
                )
                self.logAdded.emit(
                    f"ä¸­å¿ƒç‚¹: ({result['center_x']}, {result['center_y']})", "success"
                )
                self.logAdded.emit(f"ç½®ä¿¡åº¦: {result['confidence']:.3f}", "success")
                self.logAdded.emit(f"åŒ¹é…æ–¹æ³•: {result['method']}", "info")

                # åˆ›å»ºå±å¹•æˆªå›¾ç»“æœå¹¶æ˜¾ç¤º
                self._showScreenMatchResult(result)
            else:
                self.logAdded.emit("å±å¹•åŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°åŒ¹é…é¡¹", "warning")

        except Exception as e:
            self.logAdded.emit(f"å±å¹•åŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeORBMatching(self):
        """æ‰§è¡ŒORBç‰¹å¾åŒ¹é…"""
        try:
            import cv2
            import tempfile

            config = self.getCurrentAlgorithmSettings()

            # è¯»å–å›¾ç‰‡
            template = cv2.imread(self._image1_path, cv2.IMREAD_COLOR)
            target = cv2.imread(self._image2_path, cv2.IMREAD_COLOR)

            if template is None or target is None:
                self.logAdded.emit("æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶", "error")
                return

            self.logAdded.emit("å¼€å§‹ORBç‰¹å¾åŒ¹é…", "info")
            self.logAdded.emit(
                f"ORBå‚æ•°: nfeatures={config.get('nfeatures', 1000)}, "
                f"scaleFactor={config.get('scaleFactor', 1.2)}",
                "info",
            )

            # æ‰§è¡ŒORBåŒ¹é…
            result = orb_matcher.match_features(template, target, config)

            if result and result["num_matches"] >= config.get("min_matches", 10):
                # åŒ¹é…æˆåŠŸ
                self.logAdded.emit("âœ… ORBç‰¹å¾åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡ä¿¡æ¯:", "info")
                self.logAdded.emit(
                    f"  â€¢ æ€»åŒ¹é…ç‚¹æ•°: {result['num_matches']}", "success"
                )
                self.logAdded.emit(f"  â€¢ å†…ç‚¹æ•°é‡: {result['num_inliers']}", "success")
                self.logAdded.emit(
                    f"  â€¢ å†…ç‚¹æ¯”ä¾‹: {result['inlier_ratio']:.3f}", "success"
                )
                self.logAdded.emit(f"  â€¢ ç½®ä¿¡åº¦: {result['confidence']:.3f}", "success")
                self.logAdded.emit(
                    f"  â€¢ å¹³å‡è·ç¦»: {result['avg_distance']:.2f}", "info"
                )

                if result["center_point"]:
                    center = result["center_point"]
                    self.logAdded.emit(
                        f"  â€¢ åŒ¹é…ä¸­å¿ƒ: ({center['x']}, {center['y']})", "success"
                    )

                if result["bounding_box"]:
                    bbox = result["bounding_box"]
                    self.logAdded.emit(
                        f"  â€¢ è¾¹ç•Œæ¡†: {bbox['width']}x{bbox['height']} åƒç´ ", "info"
                    )

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showORBMatchResult(template, target, result)

            else:
                if result:
                    self.logAdded.emit(
                        f"ORBåŒ¹é…å¤±è´¥ï¼ŒåŒ¹é…ç‚¹æ•° {result['num_matches']} å°‘äºæœ€å°è¦æ±‚ {config.get('min_matches', 10)}",
                        "warning",
                    )
                else:
                    self.logAdded.emit("ORBåŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°è¶³å¤Ÿçš„åŒ¹é…ç‚¹", "warning")

        except Exception as e:
            self.logAdded.emit(f"ORBç‰¹å¾åŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeScreenORBMatching(self):
        """æ‰§è¡Œå±å¹•ORBç‰¹å¾åŒ¹é…"""
        try:
            import cv2
            import tempfile

            config = self.getCurrentAlgorithmSettings()

            # è¯»å–æ¨¡æ¿å›¾ç‰‡
            template = cv2.imread(self._image1_path, cv2.IMREAD_COLOR)
            if template is None:
                self.logAdded.emit("æ— æ³•è¯»å–æ¨¡æ¿å›¾ç‰‡æ–‡ä»¶", "error")
                return

            self.logAdded.emit("å¼€å§‹å±å¹•ORBç‰¹å¾åŒ¹é…", "info")
            self.logAdded.emit(
                f"ORBå‚æ•°: nfeatures={config.get('nfeatures', 1000)}, "
                f"scaleFactor={config.get('scaleFactor', 1.2)}",
                "info",
            )

            # æ•è·çª—å£æˆªå›¾
            window_screenshot = screen_capture.capture_window(
                self._selected_window, self._selected_window_rect
            )

            if window_screenshot is None:
                self.logAdded.emit("çª—å£æˆªå›¾å¤±è´¥", "error")
                return

            # æ‰§è¡ŒORBåŒ¹é…
            result = orb_matcher.match_features(template, window_screenshot, config)

            if result and result["num_matches"] >= config.get("min_matches", 10):
                # åŒ¹é…æˆåŠŸ
                self.logAdded.emit("âœ… å±å¹•ORBç‰¹å¾åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡ä¿¡æ¯:", "info")
                self.logAdded.emit(
                    f"  â€¢ æ€»åŒ¹é…ç‚¹æ•°: {result['num_matches']}", "success"
                )
                self.logAdded.emit(f"  â€¢ å†…ç‚¹æ•°é‡: {result['num_inliers']}", "success")
                self.logAdded.emit(
                    f"  â€¢ å†…ç‚¹æ¯”ä¾‹: {result['inlier_ratio']:.3f}", "success"
                )
                self.logAdded.emit(f"  â€¢ ç½®ä¿¡åº¦: {result['confidence']:.3f}", "success")
                self.logAdded.emit(
                    f"  â€¢ å¹³å‡è·ç¦»: {result['avg_distance']:.2f}", "info"
                )

                if result["center_point"]:
                    center = result["center_point"]
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡ï¼Œå†è°ƒæ•´åˆ°å±å¹•åæ ‡
                    logical_x = center["x"] / screen_capture.dpi_scale
                    logical_y = center["y"] / screen_capture.dpi_scale
                    screen_x = logical_x + self._selected_window_rect["x"]
                    screen_y = logical_y + self._selected_window_rect["y"]
                    
                    logger.info(f"ORBåŒ¹é…åæ ‡è½¬æ¢:")
                    logger.info(f"  ç‰©ç†åæ ‡: ({center['x']}, {center['y']})")
                    logger.info(f"  é€»è¾‘åæ ‡: ({logical_x:.1f}, {logical_y:.1f})")
                    logger.info(f"  å±å¹•åæ ‡: ({screen_x:.1f}, {screen_y:.1f})")
                    logger.info(f"  DPIç¼©æ”¾: {screen_capture.dpi_scale}")
                    
                    self.logAdded.emit(
                        f"  â€¢ å±å¹•åæ ‡: ({screen_x:.1f}, {screen_y:.1f})", "success"
                    )

                if result["bounding_box"]:
                    bbox = result["bounding_box"]
                    self.logAdded.emit(
                        f"  â€¢ è¾¹ç•Œæ¡†: {bbox['width']}x{bbox['height']} åƒç´ ", "info"
                    )

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showScreenORBMatchResult(template, window_screenshot, result)

                # æ˜¾ç¤ºå±å¹•è¦†ç›–å±‚
                if result["bounding_box"]:
                    bbox = result["bounding_box"]
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡
                    logical_left = bbox["left"] / screen_capture.dpi_scale
                    logical_top = bbox["top"] / screen_capture.dpi_scale
                    logical_width = bbox["width"] / screen_capture.dpi_scale
                    logical_height = bbox["height"] / screen_capture.dpi_scale
                    
                    screen_x = logical_left + self._selected_window_rect["x"]
                    screen_y = logical_top + self._selected_window_rect["y"]
                    
                    self.showScreenMatchOverlay.emit(
                        screen_x,
                        screen_y,
                        logical_width,
                        logical_height,
                        result["confidence"],
                        "ORBç‰¹å¾åŒ¹é…",
                    )

            else:
                if result:
                    self.logAdded.emit(
                        f"å±å¹•ORBåŒ¹é…å¤±è´¥ï¼ŒåŒ¹é…ç‚¹æ•° {result['num_matches']} å°‘äºæœ€å°è¦æ±‚ {config.get('min_matches', 10)}",
                        "warning",
                    )
                else:
                    self.logAdded.emit("å±å¹•ORBåŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°è¶³å¤Ÿçš„åŒ¹é…ç‚¹", "warning")

        except Exception as e:
            self.logAdded.emit(f"å±å¹•ORBç‰¹å¾åŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeScreenYOLOORBMatching(self):
        """æ‰§è¡Œå±å¹•YOLO+ORBæ··åˆåŒ¹é…"""
        try:
            import cv2
            import tempfile

            config = self.getCurrentAlgorithmSettings()

            # è¯»å–æ¨¡æ¿å›¾ç‰‡
            template = cv2.imread(self._image1_path, cv2.IMREAD_COLOR)
            if template is None:
                self.logAdded.emit("æ— æ³•è¯»å–æ¨¡æ¿å›¾ç‰‡æ–‡ä»¶", "error")
                return

            self.logAdded.emit("å¼€å§‹å±å¹•YOLO+ORBæ··åˆåŒ¹é…", "info")

            # è·å–å½“å‰ç®—æ³•é…ç½®
            config = self._algorithm_settings.get(self._algorithm_mode, {})

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = config.get("model_path", "")
            if model_path:
                self.logAdded.emit(f"ä½¿ç”¨YOLOæ¨¡å‹: {model_path}", "info")

            # æ•è·çª—å£æˆªå›¾
            window_screenshot = screen_capture.capture_window(
                self._selected_window, self._selected_window_rect
            )

            if window_screenshot is None:
                self.logAdded.emit("çª—å£æˆªå›¾å¤±è´¥", "error")
                return

            # æ‰§è¡ŒYOLO+ORBåŒ¹é…
            result = yolo_orb_matcher.match_with_yolo_orb(
                template, window_screenshot, config
            )

            if result and result.get("confidence", 0) > 0.5:
                # åŒ¹é…æˆåŠŸ
                method = result.get("method", "YOLO+ORB")
                self.logAdded.emit(f"âœ… å±å¹•{method}åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡ä¿¡æ¯:", "info")

                if "num_matches" in result:
                    self.logAdded.emit(
                        f"  â€¢ æ€»åŒ¹é…ç‚¹æ•°: {result['num_matches']}", "success"
                    )
                if "num_inliers" in result:
                    self.logAdded.emit(
                        f"  â€¢ å†…ç‚¹æ•°é‡: {result['num_inliers']}", "success"
                    )

                self.logAdded.emit(f"  â€¢ ç½®ä¿¡åº¦: {result['confidence']:.3f}", "success")

                if "yolo_confidence" in result:
                    self.logAdded.emit(
                        f"  â€¢ YOLOç½®ä¿¡åº¦: {result['yolo_confidence']:.3f}", "info"
                    )
                if "orb_confidence" in result:
                    self.logAdded.emit(
                        f"  â€¢ ORBç½®ä¿¡åº¦: {result['orb_confidence']:.3f}", "info"
                    )

                if result.get("center_point"):
                    center = result["center_point"]
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡ï¼Œå†è°ƒæ•´åˆ°å±å¹•åæ ‡
                    logical_x = center["x"] / screen_capture.dpi_scale
                    logical_y = center["y"] / screen_capture.dpi_scale
                    screen_x = logical_x + self._selected_window_rect["x"]
                    screen_y = logical_y + self._selected_window_rect["y"]
                    
                    logger.info(f"YOLO+ORBåŒ¹é…åæ ‡è½¬æ¢:")
                    logger.info(f"  ç‰©ç†åæ ‡: ({center['x']}, {center['y']})")
                    logger.info(f"  é€»è¾‘åæ ‡: ({logical_x:.1f}, {logical_y:.1f})")
                    logger.info(f"  å±å¹•åæ ‡: ({screen_x:.1f}, {screen_y:.1f})")
                    logger.info(f"  DPIç¼©æ”¾: {screen_capture.dpi_scale}")
                    
                    self.logAdded.emit(
                        f"  â€¢ å±å¹•åæ ‡: ({screen_x:.1f}, {screen_y:.1f})", "success"
                    )

                if result.get("bounding_box"):
                    bbox = result["bounding_box"]
                    self.logAdded.emit(
                        f"  â€¢ è¾¹ç•Œæ¡†: {bbox['width']}x{bbox['height']} åƒç´ ", "info"
                    )

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showScreenYOLOORBMatchResult(template, window_screenshot, result)

                # æ˜¾ç¤ºå±å¹•è¦†ç›–å±‚
                if result.get("bounding_box"):
                    bbox = result["bounding_box"]
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡
                    logical_left = bbox["left"] / screen_capture.dpi_scale
                    logical_top = bbox["top"] / screen_capture.dpi_scale
                    logical_width = bbox["width"] / screen_capture.dpi_scale
                    logical_height = bbox["height"] / screen_capture.dpi_scale
                    
                    screen_x = logical_left + self._selected_window_rect["x"]
                    screen_y = logical_top + self._selected_window_rect["y"]
                    
                    self.showScreenMatchOverlay.emit(
                        screen_x,
                        screen_y,
                        logical_width,
                        logical_height,
                        result["confidence"],
                        method,
                    )

            else:
                self.logAdded.emit("å±å¹•YOLO+ORBæ··åˆåŒ¹é…å¤±è´¥", "warning")

        except Exception as e:
            self.logAdded.emit(f"å±å¹•YOLO+ORBåŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeScreenPureYOLOMatching(self):
        """æ‰§è¡Œå±å¹•çº¯YOLOåŒ¹é…"""
        try:
            import cv2
            import tempfile

            # æ£€æŸ¥å±å¹•åŒºåŸŸæˆªå›¾
            if not self._screen_area_image_path:
                self.logAdded.emit("è¯·å…ˆé€‰æ‹©å±å¹•åŒºåŸŸ", "error")
                return

            self.logAdded.emit("å¼€å§‹å±å¹•çº¯YOLOæ£€æµ‹", "info")

            # è·å–å½“å‰ç®—æ³•é…ç½®
            config = self._algorithm_settings.get(self._algorithm_mode, {})

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = config.get("model_path", "")
            if model_path:
                self.logAdded.emit(f"ä½¿ç”¨YOLOæ¨¡å‹: {model_path}", "info")
            else:
                self.logAdded.emit("ä½¿ç”¨æ¨¡æ‹ŸYOLOæ£€æµ‹è¿›è¡Œæ¼”ç¤º", "info")

            # è¯»å–å±å¹•æˆªå›¾
            window_screenshot = cv2.imread(
                self._screen_area_image_path, cv2.IMREAD_COLOR
            )

            if window_screenshot is None:
                self.logAdded.emit("å±å¹•æˆªå›¾åŠ è½½å¤±è´¥", "error")
                return

            # å¯¹äºçº¯YOLOï¼Œæˆ‘ä»¬åªéœ€è¦æ£€æµ‹çª—å£æˆªå›¾ä¸­çš„å¯¹è±¡ï¼Œä¸éœ€è¦æ¨¡æ¿
            # ç›´æ¥ä½¿ç”¨YOLOæ£€æµ‹å™¨æ£€æµ‹æ‰€æœ‰å¯¹è±¡
            detections = pure_yolo_matcher.detect_objects_yolo(
                window_screenshot, config
            )

            if detections:
                # æ„é€ ç»“æœï¼Œä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ä½œä¸ºä¸»è¦ç»“æœ
                best_detection = max(detections, key=lambda x: x.get("confidence", 0))
                result = {
                    "x": best_detection["x"],
                    "y": best_detection["y"],
                    "width": best_detection["width"],
                    "height": best_detection["height"],
                    "confidence": best_detection["confidence"],
                    "class_name": best_detection.get("class_name", "unknown"),
                    "class_id": best_detection.get("class_id", -1),
                    "method": "Pure_YOLO_Screen",
                    "detection_count": len(detections),
                    "all_detections": detections,
                }
            else:
                result = None
                # æ£€æµ‹å¤±è´¥ï¼Œè¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                model_path = config.get("model_path", "")
                if not model_path or not model_path.strip():
                    self.logAdded.emit("âŒ YOLOæ£€æµ‹å¤±è´¥ï¼šæœªè®¾ç½®æ¨¡å‹æ–‡ä»¶", "error")
                    self.logAdded.emit("è¯·åœ¨ç®—æ³•å‚æ•°è®¾ç½®ä¸­é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶", "info")
                    self.logAdded.emit("æ”¯æŒæ ¼å¼ï¼š.ptï¼ˆæ¨èï¼‰ã€.onnxã€.weights", "info")
                elif not os.path.exists(model_path):
                    self.logAdded.emit(f"âŒ YOLOæ£€æµ‹å¤±è´¥ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨", "error")
                    self.logAdded.emit(f"æ–‡ä»¶è·¯å¾„ï¼š{model_path}", "error")
                    self.logAdded.emit("è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®", "info")
                elif not any(
                    model_path.endswith(ext) for ext in [".onnx", ".pt", ".weights"]
                ):
                    self.logAdded.emit(f"âŒ YOLOæ£€æµ‹å¤±è´¥ï¼šä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼", "error")
                    self.logAdded.emit(
                        f"å½“å‰æ–‡ä»¶ï¼š{os.path.basename(model_path)}", "error"
                    )
                    self.logAdded.emit("æ”¯æŒæ ¼å¼ï¼š.ptï¼ˆæ¨èï¼‰ã€.onnxã€.weights", "info")
                else:
                    self.logAdded.emit("âŒ YOLOæ£€æµ‹å¤±è´¥ï¼šæ¨¡å‹åŠ è½½æˆ–æ¨ç†é”™è¯¯", "error")
                    self.logAdded.emit(
                        "å¯èƒ½åŸå› ï¼šæ¨¡å‹æ–‡ä»¶æŸåã€æ ¼å¼ä¸å…¼å®¹æˆ–ç¼ºå°‘ä¾èµ–", "warning"
                    )
                    if model_path.endswith(".pt"):
                        self.logAdded.emit(
                            "å»ºè®®å®‰è£…: pip install torch ultralytics", "info"
                        )
                    elif model_path.endswith(".onnx"):
                        self.logAdded.emit(
                            "å»ºè®®å®‰è£…: pip install ultralyticsï¼ˆä¼˜å…ˆï¼‰æˆ–ä½¿ç”¨OpenCV",
                            "info",
                        )
                    elif model_path.endswith(".weights"):
                        self.logAdded.emit(
                            "å»ºè®®è½¬æ¢ä¸º.ptæ ¼å¼æˆ–æä¾›.cfgå’Œ.namesæ–‡ä»¶", "info"
                        )
                return

            if result:
                confidence = result.get("confidence", 0)
                class_name = result.get("class_name", "unknown")
                detection_count = result.get("detection_count", 1)
                all_detections = result.get("all_detections", [])

                self.logAdded.emit("âœ… å±å¹•çº¯YOLOåŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"  â€¢ æ£€æµ‹åˆ° {detection_count} ä¸ªç›®æ ‡", "info")
                self.logAdded.emit(f"  â€¢ ä¸»è¦ç±»åˆ«: {class_name}", "info")
                self.logAdded.emit(f"  â€¢ æœ€é«˜ç½®ä¿¡åº¦: {confidence:.3f}", "info")

                if result.get("x") is not None:
                    x, y = result["x"], result["y"]
                    w, h = result["width"], result["height"]
                    self.logAdded.emit(f"  â€¢ ä¸»è¦ä½ç½®: ({x}, {y})", "success")
                    self.logAdded.emit(f"  â€¢ ä¸»è¦å°ºå¯¸: {w}x{h} åƒç´ ", "info")

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showScreenPureYOLOMatchResult(None, window_screenshot, result)

                # å‘é€å¤šä¸ªæ£€æµ‹ç»“æœåˆ°å‰ç«¯æ˜¾ç¤º
                if all_detections:
                    # è½¬æ¢åæ ‡åˆ°å±å¹•åæ ‡ç³»å’Œç›¸å¯¹åæ ‡
                    screen_detections = []
                    
                    # è·å–åŒºåŸŸå°ºå¯¸
                    area_width = self._selected_window_rect["width"]
                    area_height = self._selected_window_rect["height"]
                    
                    for detection in all_detections:
                        screen_detection = detection.copy()
                        
                        # YOLOæ£€æµ‹è¿”å›çš„æ˜¯ç‰©ç†åƒç´ åæ ‡ï¼Œéœ€è¦è½¬æ¢ä¸ºé€»è¾‘åæ ‡å†åŠ ä¸Šåç§»
                        # ç‰©ç†åæ ‡ -> é€»è¾‘åæ ‡
                        logical_x = detection["x"] / screen_capture.dpi_scale
                        logical_y = detection["y"] / screen_capture.dpi_scale
                        logical_width = detection["width"] / screen_capture.dpi_scale
                        logical_height = detection["height"] / screen_capture.dpi_scale
                        
                        # é€»è¾‘åæ ‡ + é€»è¾‘åç§» = å±å¹•é€»è¾‘åæ ‡
                        screen_detection["screen_x"] = (
                            self._selected_window_rect["x"] + logical_x
                        )
                        screen_detection["screen_y"] = (
                            self._selected_window_rect["y"] + logical_y
                        )
                        # æ›´æ–°å°ºå¯¸ä¸ºé€»è¾‘åæ ‡
                        screen_detection["width"] = logical_width
                        screen_detection["height"] = logical_height
                        
                        # è®¡ç®—ç›¸å¯¹åæ ‡ï¼ˆ0-1èŒƒå›´ï¼‰
                        screen_detection["relative_x"] = logical_x / area_width
                        screen_detection["relative_y"] = logical_y / area_height
                        screen_detection["relative_width"] = logical_width / area_width
                        screen_detection["relative_height"] = logical_height / area_height
                        
                        # æ·»åŠ åŠ¨æ€é¢œè‰²ä¿¡æ¯
                        class_id = detection.get("class_id", 0)
                        screen_detection["border_color"] = self._get_class_color(class_id)
                        
                        screen_detections.append(screen_detection)

                    # å‘é€æ£€æµ‹ç»“æœåˆ°å‰ç«¯
                    detections_json = json.dumps(screen_detections)
                    self.showMultipleDetections.emit(detections_json)
                else:
                    # æ˜¾ç¤ºå•ä¸ªå±å¹•åŒ¹é…è¦†ç›–å±‚ï¼ˆå‘åå…¼å®¹ï¼‰
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡
                    logical_x = x / screen_capture.dpi_scale
                    logical_y = y / screen_capture.dpi_scale
                    logical_w = w / screen_capture.dpi_scale
                    logical_h = h / screen_capture.dpi_scale
                    
                    # é€»è¾‘åæ ‡ + é€»è¾‘åç§» = å±å¹•é€»è¾‘åæ ‡
                    screen_x = self._selected_window_rect["x"] + logical_x
                    screen_y = self._selected_window_rect["y"] + logical_y

                    logger.info(f"å•ä¸ªYOLOæ£€æµ‹åæ ‡è½¬æ¢:")
                    logger.info(f"  ç‰©ç†åæ ‡: ({x}, {y}, {w}, {h})")
                    logger.info(f"  é€»è¾‘åæ ‡: ({logical_x:.1f}, {logical_y:.1f}, {logical_w:.1f}, {logical_h:.1f})")
                    logger.info(f"  å±å¹•åæ ‡: ({screen_x:.1f}, {screen_y:.1f})")

                    self.showScreenMatchOverlay.emit(
                        screen_x,
                        screen_y,
                        logical_w,
                        logical_h,
                        confidence,
                        "çº¯YOLOåŒ¹é…",
                    )

            else:
                self.logAdded.emit("å±å¹•çº¯YOLOåŒ¹é…å¤±è´¥", "warning")

        except Exception as e:
            self.logAdded.emit(f"å±å¹•çº¯YOLOåŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executeYOLOORBMatching(self):
        """æ‰§è¡ŒYOLO+ORBæ··åˆåŒ¹é…"""
        try:
            import cv2
            import tempfile

            config = self.getCurrentAlgorithmSettings()

            # è¯»å–å›¾ç‰‡
            template = cv2.imread(self._image1_path, cv2.IMREAD_COLOR)
            target = cv2.imread(self._image2_path, cv2.IMREAD_COLOR)

            if template is None or target is None:
                self.logAdded.emit("æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶", "error")
                return

            self.logAdded.emit("å¼€å§‹YOLO+ORBæ··åˆåŒ¹é…", "info")

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = config.get("model_path", "")
            if model_path:
                self.logAdded.emit(f"ä½¿ç”¨YOLOæ¨¡å‹: {model_path}", "info")

            # æ‰§è¡ŒYOLO+ORBåŒ¹é…
            result = yolo_orb_matcher.match_with_yolo_orb(template, target, config)

            if result and result.get("confidence", 0) > 0.5:
                # åŒ¹é…æˆåŠŸ
                method = result.get("method", "YOLO+ORB")
                self.logAdded.emit(f"âœ… {method}åŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡ä¿¡æ¯:", "info")

                if "num_matches" in result:
                    self.logAdded.emit(
                        f"  â€¢ æ€»åŒ¹é…ç‚¹æ•°: {result['num_matches']}", "success"
                    )
                if "num_inliers" in result:
                    self.logAdded.emit(
                        f"  â€¢ å†…ç‚¹æ•°é‡: {result['num_inliers']}", "success"
                    )

                self.logAdded.emit(f"  â€¢ ç½®ä¿¡åº¦: {result['confidence']:.3f}", "success")

                if "yolo_confidence" in result:
                    self.logAdded.emit(
                        f"  â€¢ YOLOç½®ä¿¡åº¦: {result['yolo_confidence']:.3f}", "info"
                    )
                if "orb_confidence" in result:
                    self.logAdded.emit(
                        f"  â€¢ ORBç½®ä¿¡åº¦: {result['orb_confidence']:.3f}", "info"
                    )

                if result.get("center_point"):
                    center = result["center_point"]
                    self.logAdded.emit(
                        f"  â€¢ åŒ¹é…ä¸­å¿ƒ: ({center['x']}, {center['y']})", "success"
                    )

                if result.get("bounding_box"):
                    bbox = result["bounding_box"]
                    self.logAdded.emit(
                        f"  â€¢ è¾¹ç•Œæ¡†: {bbox['width']}x{bbox['height']} åƒç´ ", "info"
                    )

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showYOLOORBMatchResult(template, target, result)

            else:
                self.logAdded.emit("YOLO+ORBæ··åˆåŒ¹é…å¤±è´¥", "warning")

        except Exception as e:
            self.logAdded.emit(f"YOLO+ORBåŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _executePureYOLOMatching(self):
        """æ‰§è¡Œçº¯YOLOåŒ¹é…"""
        try:
            import cv2

            # æ£€æŸ¥å›¾ç‰‡è·¯å¾„
            if not self._image1_path or not self._image2_path:
                self.logAdded.emit("è¯·å…ˆé€‰æ‹©ä¸¤å¼ å›¾ç‰‡", "error")
                return

            # è¯»å–å›¾ç‰‡
            template = cv2.imread(self._image1_path)
            target = cv2.imread(self._image2_path)

            if template is None or target is None:
                self.logAdded.emit("å›¾ç‰‡åŠ è½½å¤±è´¥", "error")
                return

            self.logAdded.emit("å¼€å§‹çº¯YOLOåŒ¹é…", "info")

            # è·å–å½“å‰ç®—æ³•é…ç½®
            config = self._algorithm_settings.get(self._algorithm_mode, {})

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = config.get("model_path", "")
            if model_path:
                self.logAdded.emit(f"ä½¿ç”¨YOLOæ¨¡å‹: {model_path}", "info")

            # æ‰§è¡Œçº¯YOLOåŒ¹é…
            result = pure_yolo_matcher.match_with_pure_yolo(template, target, config)

            if result:
                confidence = result.get("confidence", 0)
                class_name = result.get("class_name", "unknown")

                self.logAdded.emit("âœ… çº¯YOLOåŒ¹é…æˆåŠŸï¼", "success")
                self.logAdded.emit(f"  â€¢ æ£€æµ‹ç±»åˆ«: {class_name}", "info")
                self.logAdded.emit(f"  â€¢ ç½®ä¿¡åº¦: {confidence:.3f}", "info")

                if result.get("x") is not None:
                    x, y = result["x"], result["y"]
                    w, h = result["width"], result["height"]
                    self.logAdded.emit(f"  â€¢ ä½ç½®: ({x}, {y})", "success")
                    self.logAdded.emit(f"  â€¢ å°ºå¯¸: {w}x{h} åƒç´ ", "info")

                # åˆ›å»ºç»“æœå›¾ç‰‡å¹¶æ˜¾ç¤º
                self._showPureYOLOMatchResult(template, target, result)

            else:
                self.logAdded.emit("çº¯YOLOåŒ¹é…å¤±è´¥", "warning")

        except Exception as e:
            self.logAdded.emit(f"çº¯YOLOåŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

    def _showMatchResult(
        self, target_image, match_loc, template_w, template_h, confidence
    ):
        """æ˜¾ç¤ºåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # å¤åˆ¶ç›®æ ‡å›¾ç‰‡
            result_image = target_image.copy()

            # ç»˜åˆ¶çº¢è‰²çŸ©å½¢æ¡†
            top_left = match_loc
            bottom_right = (match_loc[0] + template_w, match_loc[1] + template_h)
            cv2.rectangle(result_image, top_left, bottom_right, (0, 0, 255), 3)

            # æ·»åŠ ç½®ä¿¡åº¦æ ‡ç­¾
            label = f"Confidence: {confidence:.3f}"
            label_pos = (match_loc[0], match_loc[1] - 10)
            cv2.putText(
                result_image,
                label,
                label_pos,
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 0, 255),
                2,
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            self.showMatchResult.emit(
                temp_file.name, f"æ¨¡æ¿åŒ¹é…ç»“æœ - ç½®ä¿¡åº¦: {confidence:.3f}"
            )

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showScreenMatchResult(self, match_result):
        """æ˜¾ç¤ºå±å¹•åŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨ä¿®å¤çš„æˆªå›¾åŠŸèƒ½æˆªå–å…¨å±
            screenshot_cv = screen_capture.capture_screen()
            if screenshot_cv is None:
                self.logAdded.emit("å…¨å±æˆªå›¾å¤±è´¥", "error")
                return

            # ç»˜åˆ¶çº¢è‰²çŸ©å½¢æ¡†
            top_left = (match_result["left"], match_result["top"])
            bottom_right = (
                match_result["left"] + match_result["width"],
                match_result["top"] + match_result["height"],
            )
            cv2.rectangle(screenshot_cv, top_left, bottom_right, (0, 0, 255), 3)

            # æ·»åŠ ç½®ä¿¡åº¦æ ‡ç­¾
            label = f"Confidence: {match_result['confidence']:.3f}"
            label_pos = (match_result["left"], match_result["top"] - 10)
            cv2.putText(
                screenshot_cv,
                label,
                label_pos,
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 0, 255),
                2,
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, screenshot_cv)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            self.showMatchResult.emit(
                temp_file.name,
                f"å±å¹•åŒ¹é…ç»“æœ - ç½®ä¿¡åº¦: {match_result['confidence']:.3f}",
            )

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºå±å¹•ç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showORBMatchResult(self, template_image, target_image, match_result):
        """æ˜¾ç¤ºORBåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨ORBåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœï¼ˆä¸æ˜¾ç¤ºæ–‡å­—ä¿¡æ¯ï¼‰
            result_image = orb_matcher.draw_matches(
                template_image, target_image, match_result, show_info_text=False
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            title = (
                f"ORBç‰¹å¾åŒ¹é…ç»“æœ - åŒ¹é…ç‚¹: {match_result['num_matches']}, "
                f"å†…ç‚¹: {match_result['num_inliers']}, "
                f"ç½®ä¿¡åº¦: {match_result['confidence']:.3f}"
            )

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºORBç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showScreenORBMatchResult(
        self, template_image, window_screenshot, match_result
    ):
        """æ˜¾ç¤ºå±å¹•ORBåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨ORBåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœï¼ˆä¸æ˜¾ç¤ºæ–‡å­—ä¿¡æ¯ï¼‰
            result_image = orb_matcher.draw_matches(
                template_image, window_screenshot, match_result, show_info_text=False
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            title = (
                f"å±å¹•ORBç‰¹å¾åŒ¹é…ç»“æœ - åŒ¹é…ç‚¹: {match_result['num_matches']}, "
                f"å†…ç‚¹: {match_result['num_inliers']}, "
                f"ç½®ä¿¡åº¦: {match_result['confidence']:.3f}"
            )

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºå±å¹•ORBç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showScreenYOLOORBMatchResult(
        self, template_image, window_screenshot, match_result
    ):
        """æ˜¾ç¤ºå±å¹•YOLO+ORBåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨YOLO+ORBåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœ
            result_image = yolo_orb_matcher.draw_yolo_orb_result(
                template_image, window_screenshot, match_result, show_yolo_info=True
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            method = match_result.get("method", "YOLO+ORB")
            title = f"å±å¹•{method}åŒ¹é…ç»“æœ - ç½®ä¿¡åº¦: {match_result['confidence']:.3f}"

            if "yolo_confidence" in match_result and "orb_confidence" in match_result:
                title += f" (YOLO: {match_result['yolo_confidence']:.3f}, ORB: {match_result['orb_confidence']:.3f})"

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºå±å¹•YOLO+ORBç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showYOLOORBMatchResult(self, template_image, target_image, match_result):
        """æ˜¾ç¤ºYOLO+ORBåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨YOLO+ORBåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœ
            result_image = yolo_orb_matcher.draw_yolo_orb_result(
                template_image, target_image, match_result, show_yolo_info=True
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            method = match_result.get("method", "YOLO+ORB")
            title = f"{method}åŒ¹é…ç»“æœ - ç½®ä¿¡åº¦: {match_result['confidence']:.3f}"

            if "yolo_confidence" in match_result and "orb_confidence" in match_result:
                title += f" (YOLO: {match_result['yolo_confidence']:.3f}, ORB: {match_result['orb_confidence']:.3f})"

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºYOLO+ORBç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showPureYOLOMatchResult(self, template_image, target_image, match_result):
        """æ˜¾ç¤ºçº¯YOLOåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨çº¯YOLOåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœ
            result_image = pure_yolo_matcher.draw_yolo_result(
                target_image, match_result, show_confidence=True
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            class_name = match_result.get("class_name", "unknown")
            confidence = match_result.get("confidence", 0)
            title = f"çº¯YOLOåŒ¹é…ç»“æœ - ç±»åˆ«: {class_name}, ç½®ä¿¡åº¦: {confidence:.3f}"

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºçº¯YOLOç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    def _showScreenPureYOLOMatchResult(
        self, template_image, target_image, match_result
    ):
        """æ˜¾ç¤ºå±å¹•çº¯YOLOåŒ¹é…ç»“æœ"""
        try:
            import cv2
            import tempfile

            # ä½¿ç”¨çº¯YOLOåŒ¹é…å™¨ç»˜åˆ¶åŒ¹é…ç»“æœ
            result_image = pure_yolo_matcher.draw_yolo_result(
                target_image, match_result, show_confidence=True
            )

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            cv2.imwrite(temp_file.name, result_image)

            # å‘é€ä¿¡å·æ˜¾ç¤ºç»“æœ
            class_name = match_result.get("class_name", "unknown")
            confidence = match_result.get("confidence", 0)
            title = f"å±å¹•çº¯YOLOåŒ¹é…ç»“æœ - ç±»åˆ«: {class_name}, ç½®ä¿¡åº¦: {confidence:.3f}"

            self.showMatchResult.emit(temp_file.name, title)

        except Exception as e:
            self.logAdded.emit(f"åˆ›å»ºå±å¹•çº¯YOLOç»“æœå›¾ç‰‡å¤±è´¥: {str(e)}", "error")

    @Slot(str, str)
    def addLog(self, message, log_type):
        """æ·»åŠ æ—¥å¿—"""
        self.logAdded.emit(message, log_type)

    @Slot(int, str)
    def updateAlgorithmSettings(self, algorithm_index, settings_json):
        """æ›´æ–°ç®—æ³•å‚æ•°è®¾ç½®"""
        try:
            settings = json.loads(settings_json)
            if algorithm_index in self._algorithm_settings:
                self._algorithm_settings[algorithm_index].update(settings)
                
                # å¦‚æœæ›´æ–°äº†æ¨¡å‹è·¯å¾„ï¼Œéœ€è¦æ›´æ–°ç±»åˆ«é¢œè‰²æ˜ å°„
                if "model_path" in settings and settings["model_path"]:
                    self._update_model_classes(settings["model_path"])
                
                print(f"ç®—æ³• {algorithm_index} å‚æ•°å·²æ›´æ–°: {settings}")
                self.logAdded.emit(f"ç®—æ³•å‚æ•°é…ç½®å·²ä¿å­˜", "success")
            else:
                print(f"æœªçŸ¥çš„ç®—æ³•ç´¢å¼•: {algorithm_index}")
                self.logAdded.emit(f"ä¿å­˜å‚æ•°å¤±è´¥ï¼šæœªçŸ¥ç®—æ³•", "error")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            self.logAdded.emit(f"ä¿å­˜å‚æ•°å¤±è´¥ï¼šæ•°æ®æ ¼å¼é”™è¯¯", "error")
        except Exception as e:
            print(f"æ›´æ–°ç®—æ³•è®¾ç½®æ—¶å‡ºé”™: {e}")
            self.logAdded.emit(f"ä¿å­˜å‚æ•°å¤±è´¥ï¼š{str(e)}", "error")

    @Slot(int, result=str)
    def getAlgorithmSettings(self, algorithm_index):
        """è·å–ç®—æ³•å‚æ•°è®¾ç½®"""
        if algorithm_index in self._algorithm_settings:
            return json.dumps(self._algorithm_settings[algorithm_index])
        return "{}"

    def getCurrentAlgorithmSettings(self):
        """è·å–å½“å‰ç®—æ³•çš„å‚æ•°è®¾ç½®"""
        return self._algorithm_settings.get(self._algorithm_mode, {})
    
    def _generate_class_colors(self, num_classes):
        """
        åŠ¨æ€ç”Ÿæˆç±»åˆ«é¢œè‰²æ˜ å°„
        
        Args:
            num_classes: ç±»åˆ«æ•°é‡
            
        Returns:
            dict: ç±»åˆ«IDåˆ°é¢œè‰²çš„æ˜ å°„
        """
        import colorsys
        
        colors = {}
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸åŒçš„é¢œè‰²
        for i in range(num_classes):
            # ä½¿ç”¨HSVè‰²å½©ç©ºé—´ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„é¢œè‰²
            hue = i / num_classes  # è‰²ç›¸å‡åŒ€åˆ†å¸ƒ
            saturation = 0.8  # é¥±å’Œåº¦
            value = 0.9  # æ˜åº¦
            
            # è½¬æ¢ä¸ºRGB
            rgb = colorsys.hsv_to_rgb(hue, saturation, value)
            
            # è½¬æ¢ä¸º16è¿›åˆ¶é¢œè‰²å­—ç¬¦ä¸²
            hex_color = "#{:02x}{:02x}{:02x}".format(
                int(rgb[0] * 255),
                int(rgb[1] * 255),
                int(rgb[2] * 255)
            )
            
            colors[i] = hex_color
            
        logger.info(f"ä¸º {num_classes} ä¸ªç±»åˆ«ç”Ÿæˆé¢œè‰²æ˜ å°„: {colors}")
        return colors
    
    def _update_model_classes(self, model_path):
        """
        æ›´æ–°æ¨¡å‹ç±»åˆ«ä¿¡æ¯å’Œé¢œè‰²æ˜ å°„
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        try:
            # å°è¯•ä»YOLOåŒ¹é…å™¨è·å–ç±»åˆ«ä¿¡æ¯
            if self._algorithm_mode == 3:  # çº¯YOLO
                model_info = pure_yolo_matcher.get_model_info(model_path)
                if model_info:
                    self._model_classes = model_info.get("classes", {})
                    num_classes = len(self._model_classes) if self._model_classes else 80  # COCOé»˜è®¤80ç±»
                    
                    # ç”Ÿæˆé¢œè‰²æ˜ å°„
                    self._class_colors = self._generate_class_colors(num_classes)
                    
                    self.logAdded.emit(f"åŠ è½½æ¨¡å‹ç±»åˆ«ä¿¡æ¯: {num_classes} ä¸ªç±»åˆ«", "success")
                else:
                    # ä½¿ç”¨é»˜è®¤è®¾ç½®
                    self._model_classes = {}
                    self._class_colors = self._generate_class_colors(80)  # COCOé»˜è®¤
                    self.logAdded.emit("ä½¿ç”¨é»˜è®¤ç±»åˆ«è®¾ç½® (80ç±»)", "info")
            elif self._algorithm_mode == 2:  # YOLO+ORB
                model_info = yolo_orb_matcher.get_model_info(model_path)
                if model_info:
                    self._model_classes = model_info.get("classes", {})
                    num_classes = len(self._model_classes) if self._model_classes else 80
                    self._class_colors = self._generate_class_colors(num_classes)
                    self.logAdded.emit(f"åŠ è½½YOLO+ORBæ¨¡å‹ç±»åˆ«ä¿¡æ¯: {num_classes} ä¸ªç±»åˆ«", "success")
                else:
                    self._model_classes = {}
                    self._class_colors = self._generate_class_colors(80)
                    self.logAdded.emit("ä½¿ç”¨é»˜è®¤YOLO+ORBç±»åˆ«è®¾ç½® (80ç±»)", "info")
                    
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨¡å‹ç±»åˆ«ä¿¡æ¯å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤è®¾ç½®
            self._model_classes = {}
            self._class_colors = self._generate_class_colors(80)
            self.logAdded.emit("ä½¿ç”¨é»˜è®¤ç±»åˆ«è®¾ç½®", "warning")
    
    def _get_class_color(self, class_id):
        """
        è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²
        
        Args:
            class_id: ç±»åˆ«ID
            
        Returns:
            str: 16è¿›åˆ¶é¢œè‰²å­—ç¬¦ä¸²
        """
        if class_id in self._class_colors:
            return self._class_colors[class_id]
        else:
            # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰é¢œè‰²ï¼ŒåŠ¨æ€ç”Ÿæˆä¸€ä¸ª
            import colorsys
            hue = (class_id * 137.508) % 360 / 360  # ä½¿ç”¨é»„é‡‘è§’åˆ†å‰²äº§ç”Ÿå‡åŒ€åˆ†å¸ƒ
            saturation = 0.8
            value = 0.9
            rgb = colorsys.hsv_to_rgb(hue, saturation, value)
            hex_color = "#{:02x}{:02x}{:02x}".format(
                int(rgb[0] * 255),
                int(rgb[1] * 255),
                int(rgb[2] * 255)
            )
            # ç¼“å­˜è¿™ä¸ªé¢œè‰²
            self._class_colors[class_id] = hex_color
            return hex_color

    @Slot()
    def startRealtimeDetection(self):
        """å¼€å§‹å®æ—¶æ£€æµ‹"""
        if self._realtime_detection_active:
            return
            
        # æ¸…é™¤ä¹‹å‰çš„æ£€æµ‹ç»“æœ
        self.clearAllDetections.emit()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é€‰æ‹©çš„åŒºåŸŸ
        if (not self._selected_window_rect or 
            self._selected_window_rect.get("width", 0) <= 0 or 
            self._selected_window_rect.get("height", 0) <= 0):
            self.logAdded.emit("è¯·å…ˆé€‰æ‹©æ£€æµ‹åŒºåŸŸ", "error")
            return
            
        # åªæœ‰çº¯YOLOæ¨¡å¼æ”¯æŒå®æ—¶æ£€æµ‹
        if self._algorithm_mode != 3:
            self.logAdded.emit("å®æ—¶æ£€æµ‹ä»…æ”¯æŒçº¯YOLOæ¨¡å¼", "warning")
            return
            
        self._realtime_detection_active = True
        self._setupRealtimeTimer()
        self.realtimeDetectionStateChanged.emit(True)
        self.logAdded.emit("å¼€å§‹å®æ—¶YOLOæ£€æµ‹", "success")

    @Slot()
    def stopRealtimeDetection(self):
        """åœæ­¢å®æ—¶æ£€æµ‹"""
        if not self._realtime_detection_active:
            return
            
        self._realtime_detection_active = False
        if self._realtime_timer:
            self._realtime_timer.stop()
            self._realtime_timer = None
        
        # æ¸…é™¤æ‰€æœ‰æ£€æµ‹ç»“æœ
        self.clearAllDetections.emit()
        self.realtimeDetectionStateChanged.emit(False)
        self.logAdded.emit("åœæ­¢å®æ—¶æ£€æµ‹", "info")

    @Slot(int)
    def setRealtimeInterval(self, interval_ms):
        """è®¾ç½®å®æ—¶æ£€æµ‹é—´éš”ï¼ˆæ¯«ç§’ï¼‰"""
        self._realtime_interval = max(100, min(5000, interval_ms))  # é™åˆ¶åœ¨100ms-5sä¹‹é—´
        if self._realtime_timer and self._realtime_detection_active:
            self._realtime_timer.setInterval(self._realtime_interval)

    @Property(bool, notify=realtimeDetectionStateChanged)
    def realtimeDetectionActive(self):
        """å®æ—¶æ£€æµ‹çŠ¶æ€å±æ€§"""
        return self._realtime_detection_active

    def _setupRealtimeTimer(self):
        """è®¾ç½®å®æ—¶æ£€æµ‹å®šæ—¶å™¨"""
        from PySide6.QtCore import QTimer
        
        if self._realtime_timer:
            self._realtime_timer.stop()
            
        self._realtime_timer = QTimer()
        self._realtime_timer.timeout.connect(self._performRealtimeDetection)
        self._realtime_timer.setInterval(self._realtime_interval)
        self._realtime_timer.start()

    def _performRealtimeDetection(self):
        """æ‰§è¡Œä¸€æ¬¡å®æ—¶æ£€æµ‹"""
        if not self._realtime_detection_active:
            return
            
        try:
            # è·å–å½“å‰ç®—æ³•é…ç½®
            config = self._algorithm_settings.get(self._algorithm_mode, {})
            
            # è·å–QMLä¼ é€’çš„é€»è¾‘åæ ‡
            logical_x = self._selected_window_rect["x"]
            logical_y = self._selected_window_rect["y"]
            logical_width = self._selected_window_rect["width"]
            logical_height = self._selected_window_rect["height"]
            
            # å°†é€»è¾‘åæ ‡è½¬æ¢ä¸ºç‰©ç†åæ ‡
            physical_x = int(logical_x * screen_capture.dpi_scale)
            physical_y = int(logical_y * screen_capture.dpi_scale)
            physical_width = int(logical_width * screen_capture.dpi_scale)
            physical_height = int(logical_height * screen_capture.dpi_scale)
            
            region = (physical_x, physical_y, physical_width, physical_height)
            
            # æˆªå–å±å¹•åŒºåŸŸ
            screenshot_cv = screen_capture.capture_screen(region)
            
            if screenshot_cv is None:
                return
                
            # æ‰§è¡ŒYOLOæ£€æµ‹
            result = pure_yolo_matcher.match_with_pure_yolo(None, screenshot_cv, config)
            
            if result and result.get("all_detections"):
                # è½¬æ¢æ£€æµ‹ç»“æœåæ ‡
                all_detections = result["all_detections"]
                screen_detections = []
                
                # è·å–åŒºåŸŸå°ºå¯¸
                area_width = self._selected_window_rect["width"]
                area_height = self._selected_window_rect["height"]
                
                for detection in all_detections:
                    screen_detection = detection.copy()
                    
                    # ç‰©ç†åæ ‡è½¬æ¢ä¸ºé€»è¾‘åæ ‡
                    logical_det_x = detection["x"] / screen_capture.dpi_scale
                    logical_det_y = detection["y"] / screen_capture.dpi_scale
                    logical_det_width = detection["width"] / screen_capture.dpi_scale
                    logical_det_height = detection["height"] / screen_capture.dpi_scale
                    
                    # é€»è¾‘åæ ‡ + é€»è¾‘åç§» = å±å¹•é€»è¾‘åæ ‡
                    screen_detection["screen_x"] = logical_x + logical_det_x
                    screen_detection["screen_y"] = logical_y + logical_det_y
                    screen_detection["width"] = logical_det_width
                    screen_detection["height"] = logical_det_height
                    
                    # è®¡ç®—ç›¸å¯¹åæ ‡ï¼ˆ0-1èŒƒå›´ï¼‰
                    screen_detection["relative_x"] = logical_det_x / area_width
                    screen_detection["relative_y"] = logical_det_y / area_height
                    screen_detection["relative_width"] = logical_det_width / area_width
                    screen_detection["relative_height"] = logical_det_height / area_height
                    
                    # æ·»åŠ åŠ¨æ€é¢œè‰²ä¿¡æ¯
                    class_id = detection.get("class_id", 0)
                    screen_detection["border_color"] = self._get_class_color(class_id)
                    
                    screen_detections.append(screen_detection)
                
                # å‘é€æ£€æµ‹ç»“æœåˆ°å‰ç«¯ï¼ˆå®æ—¶æ›´æ–°ï¼‰
                detections_json = json.dumps(screen_detections)
                self.showMultipleDetections.emit(detections_json)
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œæ¸…é™¤æ˜¾ç¤º
                self.clearAllDetections.emit()
                
        except Exception as e:
            logger.error(f"å®æ—¶æ£€æµ‹é”™è¯¯: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶åœæ­¢å®æ—¶æ£€æµ‹
            self.stopRealtimeDetection()

    @Slot(str, result=str)
    def executeTemplateMatching(self, template_path):
        """æ‰§è¡Œæ¨¡æ¿åŒ¹é…"""
        try:
            if self._algorithm_mode != 0:
                self.logAdded.emit("å½“å‰ç®—æ³•ä¸æ˜¯æ¨¡æ¿åŒ¹é…æ¨¡å¼", "error")
                return json.dumps({"success": False, "error": "ç®—æ³•æ¨¡å¼é”™è¯¯"})

            if not template_path or not os.path.exists(template_path):
                self.logAdded.emit("æ¨¡æ¿å›¾ç‰‡è·¯å¾„æ— æ•ˆ", "error")
                return json.dumps({"success": False, "error": "å›¾ç‰‡è·¯å¾„æ— æ•ˆ"})

            # è·å–å½“å‰ç®—æ³•è®¾ç½®
            config = self.getCurrentAlgorithmSettings()
            self.logAdded.emit(f"å¼€å§‹æ¨¡æ¿åŒ¹é…ï¼Œé…ç½®: {config}", "info")

            # æ‰§è¡ŒåŒ¹é…
            result = template_matcher.find_template_on_screen(template_path, config)

            if result:
                self.logAdded.emit(
                    f"åŒ¹é…æˆåŠŸï¼ä½ç½®: ({result['center_x']}, {result['center_y']}), "
                    f"ç½®ä¿¡åº¦: {result['confidence']:.3f}",
                    "success",
                )
                return json.dumps({"success": True, "result": result})
            else:
                self.logAdded.emit("æœªæ‰¾åˆ°åŒ¹é…çš„æ¨¡æ¿", "warning")
                return json.dumps({"success": False, "error": "æœªæ‰¾åˆ°åŒ¹é…é¡¹"})

        except Exception as e:
            error_msg = f"æ¨¡æ¿åŒ¹é…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            self.logAdded.emit(error_msg, "error")
            return json.dumps({"success": False, "error": error_msg})

    @Slot(str, result=bool)
    def clickTemplate(self, template_path):
        """æŸ¥æ‰¾å¹¶ç‚¹å‡»æ¨¡æ¿"""
        try:
            if self._algorithm_mode != 0:
                self.logAdded.emit("å½“å‰ç®—æ³•ä¸æ˜¯æ¨¡æ¿åŒ¹é…æ¨¡å¼", "error")
                return False

            if not template_path or not os.path.exists(template_path):
                self.logAdded.emit("æ¨¡æ¿å›¾ç‰‡è·¯å¾„æ— æ•ˆ", "error")
                return False

            # è·å–å½“å‰ç®—æ³•è®¾ç½®
            config = self.getCurrentAlgorithmSettings()
            self.logAdded.emit(f"å¼€å§‹æŸ¥æ‰¾å¹¶ç‚¹å‡»æ¨¡æ¿", "info")

            # æ‰§è¡Œç‚¹å‡»
            success = template_matcher.click_template(template_path, config)

            if success:
                self.logAdded.emit("æˆåŠŸç‚¹å‡»æ¨¡æ¿ä½ç½®", "success")
            else:
                self.logAdded.emit("ç‚¹å‡»å¤±è´¥", "error")

            return success

        except Exception as e:
            error_msg = f"ç‚¹å‡»æ¨¡æ¿è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            self.logAdded.emit(error_msg, "error")
            return False

    @Slot(result=str)
    def getAllWindows(self):
        """è·å–æ‰€æœ‰çª—å£åˆ—è¡¨"""
        try:
            from python.windows_select import get_all_windows_list

            windows_data = get_all_windows_list()
            return json.dumps(windows_data)

        except Exception as e:
            self.logAdded.emit(f"è·å–çª—å£åˆ—è¡¨å¤±è´¥: {str(e)}", "error")
            return json.dumps([])


class ImageMatcherApp:
    def __init__(self):
        # å¯ç”¨é«˜DPIæ”¯æŒ

        self.app = QGuiApplication(sys.argv)
        self.controller = ImageMatcherController()

        # è®¾ç½®QMLæ ·å¼ä¸ºMaterialä»¥æ”¯æŒè‡ªå®šä¹‰æ ·å¼
        os.environ["QT_QUICK_CONTROLS_STYLE"] = "Material"

        # åˆ›å»ºQMLå¼•æ“
        self.engine = QQmlApplicationEngine()

        # æ³¨å†Œæ§åˆ¶å™¨åˆ°QMLä¸Šä¸‹æ–‡
        self.engine.rootContext().setContextProperty("controller", self.controller)

        # è®¾ç½®QMLæ–‡ä»¶è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        main_qml_path = os.path.join(current_dir, "main.qml")

        # åŠ è½½ä¸»QMLæ–‡ä»¶
        self.engine.load(QUrl.fromLocalFile(main_qml_path))

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½
        if not self.engine.rootObjects():
            sys.exit(-1)

    def run(self):
        """è¿è¡Œåº”ç”¨ç¨‹åº"""
        return self.app.exec()


if __name__ == "__main__":
    # 1. é¦–å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨ä»»ä½•Qtæ“ä½œä¹‹å‰ï¼‰
    os.environ["QT_ENABLE_HIGHDPI_SCALING"] = "1"
    os.environ["QT_AUTO_SCREEN_SCALE_FACTOR"] = "1"

    # 2. è®¾ç½®Windows DPIæ„ŸçŸ¥ï¼ˆåœ¨åˆ›å»ºä»»ä½•GUIä¹‹å‰ï¼‰
    if os.name == "nt":
        try:
            # è®¾ç½®è¿›ç¨‹DPIæ„ŸçŸ¥ï¼Œé˜²æ­¢pyautoguiå’ŒPySide6å†²çª
            import ctypes
            from ctypes import wintypes

            # å°è¯•ä½¿ç”¨æœ€æ–°çš„DPIæ„ŸçŸ¥API
            try:
                # Windows 10 1703åŠä»¥ä¸Šç‰ˆæœ¬
                ctypes.windll.user32.SetProcessDpiAwarenessContext(
                    -4
                )  # DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2
            except:
                try:
                    # Windows 8.1åŠä»¥ä¸Šç‰ˆæœ¬
                    ctypes.windll.shcore.SetProcessDpiAwareness(
                        2
                    )  # PROCESS_PER_MONITOR_DPI_AWARE
                except:
                    try:
                        # Windows VistaåŠä»¥ä¸Šç‰ˆæœ¬
                        ctypes.windll.user32.SetProcessDPIAware()
                    except:
                        pass
        except Exception as e:
            print(f"DPIè®¾ç½®è­¦å‘Šï¼ˆå¯å¿½ç•¥ï¼‰: {e}")

    # 3. è®¾ç½®Qté«˜DPIç¼©æ”¾ç­–ç•¥
    # ä½¿ç”¨PassThroughç­–ç•¥ç¡®ä¿ç²¾ç¡®çš„DPIå¤„ç†
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )
    
    # 4. é…ç½®pyautoguiä»¥é€‚åº”é«˜DPIç¯å¢ƒ
    try:
        import pyautogui
        # ç¦ç”¨pyautoguiçš„fail-safeåŠŸèƒ½
        pyautogui.FAILSAFE = False
        # è®¾ç½®pyautoguiçš„å›¾åƒæœç´¢ç½®ä¿¡åº¦
        pyautogui.MINIMUM_DURATION = 0.1
    except ImportError:
        pass

    app = ImageMatcherApp()
    sys.exit(app.run())
